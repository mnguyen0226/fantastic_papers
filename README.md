# Fantastic Papers and Where to Find Them

## Deep Learning Fundamentals

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

## Trustworthy Machine Learning in Computer Vision
### 1. Training-time Attacks - Poisoning Attacks

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
Solans et al. | [Poisoning Attacks on Algorithmic Fairness](https://link.springer.com/chapter/10.1007/978-3-030-67658-2_10) | Springer 2020 |  |  |  |  |
Li et al. | [Data poisoning attacks on factorization-based collaborative filtering](https://proceedings.neurips.cc/paper/2016/hash/83fa5a432ae55c253d0e60dbfa716723-Abstract.html) | NeurIPS 2016 |  |  |  |  |
Huang et al. | [Metapoison: Practical general-purpose clean-label data poisoning](https://proceedings.neurips.cc/paper/2020/hash/8ce6fc704072e351679ac97d4a985574-Abstract.html) | NeurIPS 2020 |  |  |  |  |
Shan et al. | [Fawkes: Protecting Privacy against Unauthorized Deep Learning Models](https://www.usenix.org/conference/usenixsecurity20/presentation/shan) | USENIX Security Symposium 2020 |  |  |  |  |
Shafahi et al. | [Poison frogs! targeted clean-label poisoning attacks on neural networks](https://proceedings.neurips.cc/paper/2018/hash/22722a343513ed45f14905eb07621686-Abstract.html) | NeurIPS 2018 |  |  |  |  |
Zhu et al. | [Transferable Clean-Label Poisoning Attacks on Deep Neural Nets](http://proceedings.mlr.press/v97/zhu19a.html) | PMLR 2019 |  |  |  |  |
Schioppa et al. | [Scaling Up Influence Functions](https://arxiv.org/abs/2112.03052) | ArXiv 2021 |  |  |  |  |
Biggio et al. | [Poisoning Attacks against Support Vector Machines](https://arxiv.org/abs/1206.6389) | ArXiv 2012 |  |  |  |  |
Zhao et al. | [Efficient Label Contamination Attacks Against Black-Box Learning Models](https://www.ijcai.org/Proceedings/2017/0551.pdf) | IJCAI 2017 |  |  |  |  |
Koh et al. | [Understanding Black-box Predictions via Influence Functions](https://arxiv.org/abs/1703.04730) | ArXiv 2017 |  |  |  |  |
Gu et al. | [BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain](https://arxiv.org/abs/1708.06733) | ArXiv 2019 |  |  |  |  |
Liu et al. | [Trojaning Attack on Neural Networks](https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=2782&context=cstech) | Purdue University 2017 |  |  |  |  |
Yao et al. | [Latent Backdoor Attacks on Deep Neural Networks](https://dl.acm.org/doi/abs/10.1145/3319535.3354209) | ACM CCS 2019 |  |  |  |  |

### 2. Training-time Attacks - Backdoor Attacks

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
Turner et al. | [Label-Consistent Backdoor Attacks](https://arxiv.org/abs/1912.02771) | ArXiv 2019 |  |  |  |  |
 |  |  |  |  |  |  |
 |  |  |  |  |  |  |
 |  |  |  |  |  |  |
 |  |  |  |  |  |  |
 |  |  |  |  |  |  |
 |  |  |  |  |  |  |
 |  |  |  |  |  |  |
 |  |  |  |  |  |  |
 |  |  |  |  |  |  |

### 3. Training-time Defenses

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 4. Data Quality & Data Valuation

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 5. Privacy Attacks

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 6. Different Privacy

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 7. Robust Estimation

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 8. Evasion Attack

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 9. Test-Time Defenses

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 10. Certified Defenses

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 11. Federated Learning

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 12. Uncertainty Calibration

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

## Synthetic Data Generation

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

## Software Engineering

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |
