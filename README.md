# Lists of Trustworthy ML Techniques

## 1. Poisoning Attacks
- "Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks" - Shafahi et al. NeurIPS 2018. 
    - [Paper](https://github.com/mnguyen0226/trustworthy_ml_techniques/blob/main/docs/papers/Poison%20Frogs!%20Targeted%20Clean-Label%20Poisoning%20Attacks%20on%20Neural%20Networks.pdf)
    - [Code](https://github.com/ashafahi/inceptionv3-transferLearn-poison)
- "Understanding Black-box Predictions via Influence Functions" - Koh et al. ICML 2017. 
    - [Paper](https://github.com/mnguyen0226/trustworthy_ml_techniques/blob/main/docs/papers/Understanding%20Black-box%20Predictions%20via%20Influence%20Functions.pdf)
    - [Code 1](https://worksheets.codalab.org/worksheets/0x2b314dc3536b482dbba02783a24719fd/), [Code 2](https://worksheets.codalab.org/worksheets/0x2b314dc3536b482dbba02783a24719fd/)

## 2. Backdoor Attacks
- "BadNets: Identifying Vulnerabilities in Machine Learning Model Supply Chain" - Gu et al.
    - [Paper](https://github.com/mnguyen0226/trustworthy_ml_techniques/blob/main/docs/papers/BadNets:%20Identifying%20Vulnerabilities%20in%20the%20Machine%20Learning%20Model%20Supply%20Chain)
    - Code
- "Rethinking the Backdoor Attacks's Triggers: A Frequency Perspective" - Zeng et al. ICCV 2021
    - Paper
    - Code


## 3. Training-time Defense

## 4. Data Quality

## 5. Data Valuation

## 6. Privacy Attacks

## 7. Differential Privacy

## 8. Differentially Private Learning 

## 9. Robust Estimation

## 10. Evasion Attack

## 11. Test-time Defenses

## 12. Ceertified Defense

## 13. Federated Learning

## 14. Federated Learning Security

## 15. Federated Learning Privacy

## 16. Uncertainty Calibration