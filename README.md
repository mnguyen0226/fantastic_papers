# Fantastic Papers :page_facing_up: and Where to Find Them :sparkles:

## :four_leaf_clover: Deep Learning Fundamentals

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

## :four_leaf_clover: Synthetic Time-Series Data Generation

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

## :four_leaf_clover: Trustworthy Machine Learning 
### 1. Training-time Attacks - Poisoning Attacks

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
Solans et al. | [Poisoning Attacks on Algorithmic Fairness](https://link.springer.com/chapter/10.1007/978-3-030-67658-2_10) | Springer 2020 |  |  |  |  |
Li et al. | [Data poisoning attacks on factorization-based collaborative filtering](https://proceedings.neurips.cc/paper/2016/hash/83fa5a432ae55c253d0e60dbfa716723-Abstract.html) | NeurIPS 2016 |  |  |  |  |
Huang et al. | [Metapoison: Practical general-purpose clean-label data poisoning](https://proceedings.neurips.cc/paper/2020/hash/8ce6fc704072e351679ac97d4a985574-Abstract.html) | NeurIPS 2020 |  |  |  |  |
Shan et al. | [Fawkes: Protecting Privacy against Unauthorized Deep Learning Models](https://www.usenix.org/conference/usenixsecurity20/presentation/shan) | USENIX Security Symposium 2020 |  |  |  |  |
Shafahi et al. | [Poison frogs! targeted clean-label poisoning attacks on neural networks](https://proceedings.neurips.cc/paper/2018/hash/22722a343513ed45f14905eb07621686-Abstract.html) | NeurIPS 2018 |  |  |  |  |
Zhu et al. | [Transferable Clean-Label Poisoning Attacks on Deep Neural Nets](http://proceedings.mlr.press/v97/zhu19a.html) | PMLR 2019 |  |  |  |  |
Schioppa et al. | [Scaling Up Influence Functions](https://arxiv.org/abs/2112.03052) | ArXiv 2021 |  |  |  |  |
Biggio et al. | [Poisoning Attacks against Support Vector Machines](https://arxiv.org/abs/1206.6389) | ArXiv 2012 |  |  |  |  |
Zhao et al. | [Efficient Label Contamination Attacks Against Black-Box Learning Models](https://www.ijcai.org/Proceedings/2017/0551.pdf) | IJCAI 2017 |  |  |  |  |
Koh et al. | [Understanding Black-box Predictions via Influence Functions](https://arxiv.org/abs/1703.04730) | ArXiv 2017 |  |  |  |  |
Yao et al. | [Latent Backdoor Attacks on Deep Neural Networks](https://dl.acm.org/doi/abs/10.1145/3319535.3354209) | ACM CCS 2019 |  |  |  |  |

### 2. Training-time Attacks - Backdoor Attacks

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
Turner et al. | [Label-Consistent Backdoor Attacks](https://arxiv.org/abs/1912.02771) | ArXiv 2019 |  |  |  |  |
Chen et al. | [Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning](https://arxiv.org/abs/1712.05526) | ArXiv 2017 |  |  |  |  |
Gu et al. | [BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain](https://arxiv.org/abs/1708.06733) | ArXiv 2019 |  |  |  |  |
Wallace et al. | [Imitation attacks and defenses for black-box machine translation systems](https://arxiv.org/abs/2004.15015) | ArXiv 2020 |  |  |  |  |
Salem et al. | [BAAAN: Backdoor Attacks Against Autoencoder and GAN-Based Machine Learning Models](https://arxiv.org/abs/2010.03007) | ArXiV 2020 |  |  |  |  |
Wang et al. | [A Trigger Exploration Method for Backdoor Attacks on Deep Learning-Based Traffic Control Systems](https://ieeexplore.ieee.org/abstract/document/9683577?casa_token=MCrgmABy7E8AAAAA:14E5T_NDRbJMAA9QnJhfNuby8sRojqqjy-0CnQ0rT7oeBrIB2GaNGeewwJ5rjrG8QqkEh1IzBw) | IEEE 2021 |  |  |  |  |
Adi et al. | [Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring](https://www.usenix.org/conference/usenixsecurity18/presentation/adi) | USENIX Security Symposium 2018 |  |  |  |  |
Liu et al. | [Trojaning Attack on Neural Networks](https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=2782&context=cstech) | Purdue University 2017 |  |  |  |  |
Turner et al. | [Metropolis-Hastings Generative Adversarial Networks](https://proceedings.mlr.press/v97/turner19a.html) | PMLR 2019 |  |  |  |  |
Saha et al. | [Hidden Trigger Backdoor Attacks](https://ojs.aaai.org/index.php/AAAI/article/view/6871) | AAAI 2020 |  |  |  |  |

### 3. Training-time Data Poisoning Defenses

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
Wang et al | [Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks](https://ieeexplore.ieee.org/abstract/document/8835365?casa_token=czPHUrjctSgAAAAA:8HwtzpqgYvZ8lwtJAEltcf1YQ2A5rDB0fycsCRkv5JyAW8I03f0TyIgeH_0t2F9-uJkrrsEkKw) | IEEE 2019 |  |  |  |  |
Chen et al. | [DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks](http://www.aceslab.org/sites/default/files/DeepInspect.pdf) | IJCAI 2019 |  |  |  |  |
Guo et al. | [TABOR: A Highly Accurate Approach to Inspecting and Restoring Trojan Backdoors in AI Systems](https://arxiv.org/abs/1908.01763) | ArXiV 2019 |  |  |  |  |
Chen et al. | [Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting](https://arxiv.org/abs/2004.12651) | ArXiv 2020 |  |  |  |  |
Zeng et al. | [Adversarial Unlearning of Backdoors via Implicit Hypergradient](https://openreview.net/forum?id=MeeQkFYVbzW) | ICLR 2022 |  |  |  |  |
Hong et al. | [On the Effectiveness of Mitigating Data Poisoning Attacks with Gradient Shaping](https://arxiv.org/abs/2002.11497) | ArXiv 2020 |  |  |  |  |
Ma et al. | [Explaining Vulnerabilities to Adversarial Machine Learning through Visual Analytics](https://ieeexplore.ieee.org/abstract/document/8812988?casa_token=Fsw5s8_xaYEAAAAA:AK1kks88Bj-xRJn1Xq6aL4IIWxrF1DtuYCb-FaEAMpnMSPJDcH2274DgH4Y2AZZ5OhZZLQ6JBA) | IEEE 2019 |  |  |  |  |
Borgnia et al. | [Strong Data Augmentation Sanitizes Poisoning and Backdoor Attacks Without an Accuracy Tradeoff](https://ieeexplore.ieee.org/abstract/document/9414862?casa_token=lERRhmQ15WQAAAAA:VBQJNGUHR6bTSN6xy46bS8kKkm2iTAIJWgU22QmWTq3fCJ1XG023wCksKybEnsOtyud2UXO4QA) | IEEE 2021 |  |  |  |  |

### 4. Data Quality & Data Valuation

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 5. Privacy Attacks

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 6. Different Privacy

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 7. Robust Estimation

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 8. Evasion Attack

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 9. Test-Time Defenses

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 10. Certified Defenses

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 11. Federated Learning

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

### 12. Uncertainty Calibration

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

## :four_leaf_clover: Statistical Methods & Data Analytics 
Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

## :four_leaf_clover: Representative Learning
Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

## :four_leaf_clover: Sequential Learning
Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

## :four_leaf_clover: Reinforcement Learning
Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |

## :four_leaf_clover: Software Engineering

Author | Title | Publication | Code | Slide | Attempt 1 | Attempt 2 |
--- | --- | --- | --- |--- |--- |--- |
 |  |  |  |  |  |  |
